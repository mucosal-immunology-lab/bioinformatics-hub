{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Mucosal Immunology Lab Bioinformatics Hub","text":""},{"location":"#overview","title":"Overview","text":"<p>Over the years, we have refined several workflows for processing of the various omic modalities we utilise within our group. As with any workflows in the bioinformatics field, these are constantly evolving as new tools and best practices emerge. As such, this hub is very much a work-in-progress, and will remain so as we continue to add and update it.</p>"},{"location":"RNAseq/rnaseq-nfcore/","title":"Processing RNA sequencing data with nf-core","text":""},{"location":"RNAseq/rnaseq-nfcore/#overview","title":"Overview","text":"<p>Here we will describe the process for processing RNA sequencing data using the nf-core/rnaseq pipeline. This document was written as of version 3.14.0</p> <p>nf-core/rnaseq is a bioinformatics pipeline that can be used to analyse RNA sequencing data obtained from organisms with a reference genome and annotation. It takes a samplesheet and FASTQ files as input, performs quality control (QC), trimming and (pseudo-)alignment, and produces a gene expression matrix and extensive QC report.</p> <p>Full details of the pipeline and the many customisable options can be view on the pipeline website.</p> <p></p>"},{"location":"RNAseq/rnaseq-nfcore/#installation","title":"Installation","text":"<p>In this section, we discuss the installation process on the M3 MASSIVE cluster.</p>"},{"location":"RNAseq/rnaseq-nfcore/#create-nextflow-environment","title":"Create nextflow environment \ud83d\udc0d","text":"<p>To begin with, we need to create a new environment using mamba. Mamba is recommended here over conda due to its massively improved dependency solving speeds and parallel package downloading (among other reasons).</p> <pre><code># Create environment\nmamba create -n nextflow nextflow \\\n    salmon=1.10.0 fq fastqc umi_tools \\\n    trim-galore bbmap sortmerna samtools \\\n    picard stringtie bedtools rseqc \\\n    qualimap preseq multiqc subread \\\n    ucsc-bedgraphtobigwig ucsc-bedclip \\\n    bioconductor-deseq2\n\n# Activate environment\nmamba activate nextflow\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#download-and-compile-rsem","title":"Download and compile RSEM","text":"<p>RSEM is a software package for estimating gene and isoform expression levels from RNA-Seq data.</p> <pre><code># Download RSEM\ngit clone https://github.com/deweylab/RSEM\n\n# Enter the directory (RSEM) and compile\ncd RSEM; make\n</code></pre> <p>Make note of this directory for your run script so you can add this to your PATH variable.</p>"},{"location":"RNAseq/rnaseq-nfcore/#prepare-your-sample-sheet","title":"Prepare your sample sheet \u270f\ufe0f","text":"<p>You will need to have a sample sheet prepared that contains a sample name, the <code>fastq.gz</code> file paths, and the strandedness of the read files.</p> <p>If you are working with a single-ended sequencing run, leave the <code>fastq_2</code> column empty, but the header still needs to be included.</p> <p>For example, <code>samplesheet.csv</code>:</p> <pre><code>sample,fastq_1,fastq_2,strandedness\nCONTROL_REP1,AEG588A1_S1_L002_R1_001.fastq.gz,AEG588A1_S1_L002_R2_001.fastq.gz,auto\nCONTROL_REP1,AEG588A1_S1_L003_R1_001.fastq.gz,AEG588A1_S1_L003_R2_001.fastq.gz,auto\nCONTROL_REP1,AEG588A1_S1_L004_R1_001.fastq.gz,AEG588A1_S1_L004_R2_001.fastq.gz,auto\n</code></pre> <p>Each row represents a fastq file (single-end) or a pair of fastq files (paired end). Rows with the same sample identifier are considered technical replicates and merged automatically. The strandedness refers to the library preparation and will be automatically inferred if set to auto.</p>"},{"location":"RNAseq/rnaseq-nfcore/#run-the-pipeline","title":"Run the pipeline \ud83c\udf4f","text":""},{"location":"RNAseq/rnaseq-nfcore/#start-a-new-interactive-session","title":"Start a new interactive session","text":"<p>Firstly, we will start a new interactive session on the M3 MASSIVE cluster.</p> <pre><code>smux n --time=2-00:00:00 --mem=64GB --ntasks=1 --cpuspertask=12 -J nf-core/rnaseq\n</code></pre> <p>Once we are inside the interactive session, we need to select an appropriate version of the Java JDK to use. For the Nextflow pipeline we will be running, we need at least version 17+.</p> <pre><code># View available java JDK modules\nmodule avail java\n\n# Load an appropriate one (over version 17)\nmodule load java/openjdk-17.0.2\n\n# Can double-check the correct version is loaded\njava --version\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#test-your-set-up-optional","title":"Test your set-up (optional) \ud83e\uddba","text":"<p>This step is optional, but highly advisable for a first-time setup or when re-installing.</p> <pre><code>nextflow run nf-core/rnaseq -r 3.14.0 \\\n    -profile test \\\n    --outdir test \\\n    -resume \\\n    --skip-dupradar \\\n    --skip_markduplicates\n</code></pre> <ul> <li>We skip the <code>dupradar</code> step, because to install <code>bioconductor-dupradar</code>, mamba wants to downgrade <code>salmon</code> to a very early version, which is not ideal </li> <li>We also skip the <code>markduplicates</code> step because it is not recommended to remove duplicates anyway due to normal biological duplicates (i.e. there won't just be 1 copy of a given gene in a complete sample) </li> </ul>"},{"location":"RNAseq/rnaseq-nfcore/#download-genome-files","title":"Download genome files","text":"<p>To avoid issues with genome incompatibility with the version of STAR you are running, it is recommended to simply download the relevant genome fasta and GTF files using the following scripts, and then supply them directly to the function call.</p>"},{"location":"RNAseq/rnaseq-nfcore/#human-genome-files","title":"Human genome files \ud83d\udc68\ud83d\udc69","text":"01_retrieve_human_genome.sh<pre><code>#!/bin/bash\nVERSION=111\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/gtf/homo_sapiens/Homo_sapiens.GRCh38.$VERSION.gtf.gz\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#mouse-genome-files","title":"Mouse genome files \ud83d\udc01","text":"01_retrieve_mouse_genome.sh<pre><code>#!/bin/bash\nVERSION=111\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/fasta/mus_musculus/dna/Mus_musculus.GRCm39.dna_sm.primary_assembly.fa.gz\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/gtf/mus_musculus/Mus_musculus.GRCm39.$VERSION.gtf.gz\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#run-your-rna-sequencing-reads","title":"Run your RNA sequencing reads \ud83d\udc01","text":"<p>To avoid typing the whole command out (and in case the pipeline crashes), create a script that will handle the process. Two examples are given here, with one for human samples, and one for mouse samples.</p> <ul> <li>You will need to replace the RSEM folder location with your own path from above.</li> <li>Using the <code>save_reference</code> option stores the formatted genome files to save time if you need to resume or restart the pipeline.</li> </ul>"},{"location":"RNAseq/rnaseq-nfcore/#human-run-script","title":"Human run script \ud83d\udc68\ud83d\udc69","text":"02_run_rnaseq_human.sh<pre><code>#!/bin/bash\nmodule load java/openjdk-17.0.2\nexport PATH=$PATH:/home/mmacowan/mf33/tools/RSEM/\n\nnextflow run nf-core/rnaseq -r 3.14.0 \\\n    --input samplesheet.csv \\\n    --outdir rnaseq_output \\\n    --fasta /home/mmacowan/mf33/scratch_nobackup/RNA/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz \\\n    --gtf /home/mmacowan/mf33/scratch_nobackup/RNA/Homo_sapiens.GRCh38.111.gtf.gz \\\n    --skip_dupradar \\\n    --skip_markduplicates \\\n    --save_reference \\\n    -resume\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#mouse-run-script","title":"Mouse run script \ud83d\udc01","text":"02_run_rnaseq_mouse.sh<pre><code>#!/bin/bash\nmodule load java/openjdk-17.0.2\nexport PATH=$PATH:\u201d/home/mmacowan/mf33/tools/RSEM/\u201d\n\nnextflow run nf-core/rnaseq -r 3.14.0 \\\n    --input samplesheet.csv \\\n    --outdir rnaseq_output \\\n    --fasta /home/mmacowan/mf33/scratch_nobackup/RNA/Mus_musculus.GRCm39.dna_sm.primary_assembly.fa.gz \\\n    --gtf /home/mmacowan/mf33/scratch_nobackup/RNA/Mus_musculus.GRCm39.111.gtf.gz \\\n    --skip_dupradar \\\n    --skip_markduplicates \\\n    --save_reference \\\n    -resume\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#import-data-into-r","title":"Import data into R","text":"<p>We have a standardised method for importing data into R. Luckily for us, the NF-CORE/rnaseq pipeline outputs are provided in <code>.rds</code> format as <code>SummarizedExperiment</code> objects, with bias-corrected gene counts without an offset.</p> <ul> <li><code>salmon.merged.gene_counts_length_scaled.rds</code></li> </ul> <p>There are two matrices provided to us: <code>counts</code> and <code>abundance</code>.</p> <ul> <li>The <code>abundance</code> matrix is the scaled and normalised transcripts per million (TPM) abundance. TPM explicitly erases information about library size. That is, it estimates the relative abundance of each transcript proportional to the total population of transcripts sampled in the experiment. Thus, you can imagine TPM, in a way, as a partition of unity \u2014 we want to assign a fraction of the total expression (whatever that may be) to transcript, regardless of whether our library is 10M fragments or 100M fragments.</li> <li>The <code>counts</code> matrix is a re-estimated counts table that aims to provide count-level data to be compatible with downstream tools such as DESeq2.</li> <li>The <code>tximport</code> package has a single function for importing transcript-level estimates. The type argument is used to specify what software was used for estimation. A simple list with matrices, <code>\"abundance\"</code>, <code>\"counts\"</code>, and <code>\"length\"</code>, is returned, where the transcript level information is summarized to the gene-level. Typically, abundance is provided by the quantification tools as TPM (transcripts-per-million), while the counts are estimated counts (possibly fractional), and the <code>\"length\"</code> matrix contains the effective gene lengths. The <code>\"length\"</code> matrix can be used to generate an offset matrix for downstream gene-level differential analysis of count matrices.</li> </ul>"},{"location":"RNAseq/rnaseq-nfcore/#r-code-for-import-and-voom-normalisation","title":"R code for import and voom-normalisation","text":"<p>Here we show our standard process for preparing RNAseq data for downstream analysis.</p> <pre><code># Load R packages\npkgs &lt;- c('knitr', 'here', 'SummarizedExperiment', 'biomaRt', 'edgeR', 'limma')\npacman::p_load(char = pkgs)\n\n# Import the bias-corrected counts from STAR Salmon\nrna_data &lt;- readRDS(here('input', 'salmon.merged.gene_counts_length_scaled.rds'))\n\n# Get Ensembl annotations\nensembl &lt;- useMart('ensembl', dataset = 'hsapiens_gene_ensembl')\n\nensemblIDsBronch &lt;- rownames(rna_bronch)\n\ngene_list &lt;- getBM(attributes = c('ensembl_gene_id', 'hgnc_symbol', 'gene_biotype'),\n                   filters = 'ensembl_gene_id', values = ensemblIDsBronch, mart = ensembl)\ncolnames(gene_list) &lt;- c(\"gene_id\", \"hgnc_symbol\", \"gene_biotype\")\ngene_list &lt;- filter(gene_list, !duplicated(gene_id))\n\n# Ensure that only genes in the STAR Salmon outputs are kept for the gene list\nrna_data &lt;- rna_data[rownames(rna_data) %in% gene_list$gene_id, ]\n\n# Add the ENSEMBL data to the rowData element\nrowData(rna_data) &lt;- merge(gene_list, rowData(rna_data), by = \"gene_id\", all = FALSE)\n\n# Load the RNA metadata\nmetadata_rna &lt;- read_csv(here('input', 'metadata_rna.csv'))\n\n# Sort the metadata rows to match the order of the abundance data\nrownames(metadata_rna) &lt;- metadata_rna$RNA_barcode\nmetadata_rna &lt;- metadata_rna[colnames(rna_data),]\n\n# Create a DGEList from the SummarizedExperiment object\nrna_data_dge &lt;- DGEList(assay(rna_data, 'counts'), \n                        samples = metadata_rna, \n                        group = metadata_rna$group,\n                        genes = rowData(rna_data),\n                        remove.zeros = TRUE)\n\n# Filter the DGEList based on the group information\ndesign &lt;- model.matrix(~ group, data = rna_data_dge$samples)\nkeep_min10 &lt;- filterByExpr(rna_data_dge, design, min.count = 10)\nrna_data_dge_min10 &lt;- rna_data_dge[keep_min10, ]\n\n# Calculate norm factors and perform voom normalisation\nrna_data_dge_min10 &lt;- calcNormFactors(rna_data_dge_min10)\nrna_data_dge_min10 &lt;- voom(rna_data_dge_min10, design, plot = TRUE)\n\n# Add the normalised abundance data from STAR Salmon and filter to match the counts data\nrna_data_dge_min10$abundance &lt;- as.matrix(assay(rna_bronch, 'abundance'))[keep_min10, ]\n\n# Select protein coding defined genes only\nrna_data_dge_min10 &lt;- rna_data_dge_min10[rna_data_dge_min10$genes$gene_biotype == \"protein_coding\" &amp; rna_data_dge_min10$genes$hgnc_symbol != \"\", ]\n\n# Add symbol as rowname\nrownames(rna_data_dge_min10) &lt;- rna_data_dge_min10$genes$gene_name\n\n# Save the DGEList\nsaveRDS(rna_data_dge_min10, here('input', 'rna_data_dge_min10.rds'))\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#rights","title":"Rights","text":"<p>NF-CORE/rnaseq</p> <p>There are many people to thank here for writing and maintaining the NF-CORE/rnaseq pipeline (see here). If you use this pipeline for your analysis, please cite it using the following doi: 10.5281/zenodo.1400710</p> <p>This document</p> <ul> <li>Copyright \u00a9 2024 \u2013 Mucosal Immunology Lab, Melbourne VIC, Australia</li> <li>Licence: These tools are provided under the MIT licence (see LICENSE file for details)</li> <li>Authors: M. Macowan</li> </ul>"}]}