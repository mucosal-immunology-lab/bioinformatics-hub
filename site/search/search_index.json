{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Mucosal Immunology Lab Bioinformatics Hub","text":""},{"location":"#overview","title":"Overview","text":"<p>Over the years, we have refined several workflows for processing of the various omic modalities we utilise within our group. As with any workflows in the bioinformatics field, these are constantly evolving as new tools and best practices emerge. As such, this hub is very much a work-in-progress, and will remain so as we continue to add and update it.</p>"},{"location":"NextFlow/nf-mucimmuno/","title":"Nextflow Workflows","text":"<p>As they are built and published, this repository will contain Nextflow workflows for processing of different data omic modalities.</p> <p>Additionally, we may provide additional tools and code for further downstream processing, with the goal of standardising data analytic approaches within the Mucosal Immunology Lab.</p>"},{"location":"NextFlow/nf-mucimmuno/#single-cell-rnaseq-fastq-pre-processing","title":"Single-cell RNAseq FASTQ pre-processing","text":"<p>nf-mucimmuno/scRNAseq is a bioinformatics pipeline for single-cell RNA sequencing data that can be used to run quality control steps and alignment to a host genome using STARsolo. Currently only configured for use with data resulting from BD Rhapsody library preparation.</p> <p></p>"},{"location":"NextFlow/scRNAseq/","title":"Single-cell RNAseq FASTQ pre-processing","text":""},{"location":"NextFlow/scRNAseq/#introduction","title":"Introduction","text":"<p>nf-mucimmuno/scRNAseq is a bioinformatics pipeline that can be used to run quality control steps and alignment to a host genome using STARsolo. It takes a samplesheet and FASTQ files as input, performs FastQC, trimming and alignment, and produces an output <code>.tar.gz</code> archive containing the collected outputs from STARsolo, ready for further processing downstream in R. MultiQC is run on the FastQC outputs both before and after TrimGalore! for visual inspection of sample quality \u2013 output <code>.html</code> files are collected in the results.</p> <p></p>"},{"location":"NextFlow/scRNAseq/#usage","title":"Usage","text":""},{"location":"NextFlow/scRNAseq/#download-the-repository","title":"Download the repository \ud83d\udcc1","text":"<p>This repository contains the relevant Nextflow workflow components, including a conda environment and submodules, to run the pipeline. To retrieve this repository alone, run the <code>retrieve_me.sh</code> script above.</p> <p> Git <code>sparse-checkout</code> is required to retrieve just the nf-mucimmuno/scRNAseq pipeline. It was only introduced to Git in version 2.27.0, so ensure that the loaded version is high enough (or that there is a version loaded on the cluster at all). As of July 2024, the M3 MASSIVE cluster has version 2.38.1 available. </p> <pre><code># Check git version\ngit --version\n\n# Load git module if not loaded or insufficient version\nmodule load git/2.38.1\n</code></pre> <p>First, create a new bash script file.</p> <pre><code># Create and edit a new file with nano\nnano retrieve_me.sh\n</code></pre> <p>Add the contents to the file, save, and close.</p> retrieve_me.sh<pre><code>#!/bin/bash\n\n# Define variables\nREPO_URL=\"https://github.com/mucosal-immunology-lab/nf-mucimmuno\"\nREPO_DIR=\"nf-mucimmuno\"\nSUBFOLDER=\"scRNAseq\"\n\n# Clone the repository with sparse checkout\ngit clone --no-checkout $REPO_URL\ncd $REPO_DIR\n\n# Initialize sparse-checkout and set the desired subfolder\ngit sparse-checkout init --cone\ngit sparse-checkout set $SUBFOLDER\n\n# Checkout the files in the subfolder\ngit checkout main\n\n# Move the folder into the main folder and delete the parent\nmv $SUBFOLDER ../\ncd ..\nrm -rf $REPO_DIR\n\n# Extract the larger gzipped CLS files\ngunzip -r \"$SUBFOLDER/modules/starsolo/CLS\"\n\necho \"Subfolder '$SUBFOLDER' has been downloaded successfully.\"\n</code></pre> <p>Then run the script to retrieve the repository into a new folder called <code>scRNAseq</code>, which will house your workflow files and results.</p> <pre><code># Run the script\nbash retrieve_me.sh\n</code></pre>"},{"location":"NextFlow/scRNAseq/#create-the-conda-environment","title":"Create the conda environment \ud83d\udc0d","text":"<p>To create the conda environment, use the provided environment <code>.yaml</code> file. Then activate it to access required functions.</p> <pre><code># Create the environment\nmamba env create -f environment.yaml\n\n# Activate the environment\nmamba activate nextflow-scrnaseq\n</code></pre>"},{"location":"NextFlow/scRNAseq/#prepare-the-genome","title":"Prepare the genome \ud83e\uddec","text":"<p>Create a new folder somewhere to store your genome files. Enter the new folder, and run the relevant code depending on your host organism. Run these steps in an interactive session with ~48GB RAM and 16 cores, or submit them as an sbatch job.</p> <p> Please check if these are already available somewhere before regenerating them yourself! </p> <p>STAR should be loaded already via the conda environment for the genome indexing step. We will set <code>--sjdbOverhang</code> to 79 to be suitable for use with the longer <code>R2</code> FASTQ data resulting from BD Rhapsody single cell sequencing. This may require alteration for other platforms. Essentially, you just need to set <code>--sjdbOverhang</code> to the length of your R2 sequences minus 1.</p>"},{"location":"NextFlow/scRNAseq/#human-genome-files","title":"Human genome files \ud83d\udc68\ud83d\udc69","text":"01_retrieve_human_genome.sh<pre><code>#!/bin/bash\nVERSION=111\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/gtf/homo_sapiens/Homo_sapiens.GRCh38.$VERSION.gtf.gz\ngunzip *\n</code></pre> <p>Then use STAR to prepare the genome index.</p> 02_index_human_genome.sh<pre><code>#!/bin/bash\nVERSION=111\nSTAR \\\n    --runThreadN 16 \\\n    --genomeDir \"STARgenomeIndex79/\" \\\n    --runMode genomeGenerate \\\n    --genomeFastaFiles \"Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa\" \\\n    --sjdbGTFfile \"Homo_sapiens.GRCh38.$VERSION.gtf\" \\\n    --sjdbOverhang 79\n</code></pre>"},{"location":"NextFlow/scRNAseq/#mouse-genome-files","title":"Mouse genome files \ud83d\udc01","text":"01_retrieve_mouse_genome.sh<pre><code>#!/bin/bash\nVERSION=111\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/fasta/mus_musculus/dna/Mus_musculus.GRCm39.dna_sm.primary_assembly.fa.gz\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/gtf/mus_musculus/Mus_musculus.GRCm39.$VERSION.gtf.gz\ngunzip *\n</code></pre> <p>Then use STAR to prepare the genome index.</p> 02_index_mouse_genome.sh<pre><code>#!/bin/bash\nVERSION=111\nSTAR \\\n    --runThreadN 16 \\\n    --genomeDir \"STARgenomeIndex79/\" \\\n    --runMode genomeGenerate \\\n    --genomeFastaFiles \"Mus_musculus.GRCm39.dna_sm.primary_assembly.fa\" \\\n    --sjdbGTFfile \"Mus_musculus.GRCm39.$VERSION.gtf\" \\\n    --sjdbOverhang 79\n</code></pre>"},{"location":"NextFlow/scRNAseq/#prepare-your-sample-sheet","title":"Prepare your sample sheet \u270f\ufe0f","text":"<p>This pipeline requires a sample sheet to identify where your FASTQ files are located, and which cell label sequences (CLS) are being utilised.</p> <p>More information about the CLS tags used with BD Rhapsody single-cell RNAseq library preparation can be found here:</p> <ul> <li>BD Rhapsody Sequence Analysis Pipeline \u2013 User's Guide</li> <li>BD Rhapsody Cell Label Structure \u2013 Python Script</li> </ul> <p>More information about the CLS tags used with 10X Chromium single-cell RNAseq library preparation can be found here:</p> <ul> <li>10X Chromium Single Cell 3' Solution V2 and V3 guide (Teich Lab)</li> <li>10X Chromium V2 CLS sequences are 26bp long.</li> <li>10X Chromium V3 CLS sequences are 28bp long.</li> </ul> <p>The benefit of providing the name of the CLS bead versions in the sample sheet is that you can combine runs that utilise different beads together in the same workflow. Keep in mind that if you do this though, there may be some bead-related batch effects to address and correct downstream \u2013 it is always important to check for these effects when combining sequencing runs in any case. The current options are:</p> CLS option Description BD_Original The original BD rhapsody beads and linker sequences BD_Enhanced_V1 First version of enhanced beads with polyT and 5prime capture oligo types, shorter linker sequences, longer polyT, and 0-3 diversity insert bases at the beginning of the sequence BD_Enhanced_V2 Same structure as the enhanced (V1) beads, but with increased CLS diversity (384 vs. 96) 10X_Chromium_V2 Feature a 16 bp cell barcode and a 10 bp unique molecular identifier (UMI) 10X_Chromium_V3 Enhanced sequencing accuracy and resolution with a 16 bp cell barcode and a 12 bp UMI <p>Further, we also need to provide the path to the STAR genome index folder for each sample \u2013 while in many cases this value will remain constant, the benefit of providing this information is that you can process runs with different R2 sequence lengths at the same time. Recall from above that the genome index you use should use an <code>--sjdbOverhang</code> length that of your R2 sequences minus 1.</p> <p>Your sample sheet should look as follows, ensuring you use the exact column names as below. Remember that on the M3 MASSIVE cluster, you need to use the full file path \u2013 relative file paths don't usually work.</p> <pre><code>sample,fastq_1,fastq_2,CLS,GenomeIndex\nCONTROL_S1,CONTROL_S1_R1.fastq.gz,CONTROL_S1_R2.fastq.gz,BD_Enhanced_V2,mf33/Databases/ensembl/human/STARgenomeIndex79\nCONTROL_S2,CONTROL_S2_R1.fastq.gz,CONTROL_S1_R2.fastq.gz,BD_Enhanced_V2,mf33/Databases/ensembl/human/STARgenomeIndex79\nTREATMENT_S1,TREATMENT_S1_R1.fastq.gz,TREATMENT_S1_R2.fastq.gz,BD_Enhanced_V2,mf33/Databases/ensembl/human/STARgenomeIndex79\n</code></pre> <p>An example is provided in <code>data/samplesheet_test</code>.</p>"},{"location":"NextFlow/scRNAseq/#running-the-pipeline","title":"Running the pipeline \ud83c\udfc3","text":"<p>Now you can run the pipeline. You will need to set up a parent job to run each of the individual jobs \u2013 this can be either an interactive session, or an sbatch job. For example:</p> <pre><code># Start an interactive session with minimal resources\nsmux n --time=3-00:00:00 --mem=16GB --ntasks=1 --cpuspertask=2 -J nf-STARsolo\n</code></pre> <p>Make sure you alter the <code>nextflow.config</code> file to provide the path to your sample sheet, unless it is <code>./data/samplesheet.csv</code> which is the default for the cluster profile. Stay within the top <code>cluster</code> profile section to alter settings for Slurm-submitted jobs.</p> <p>Inside your interactive session, be sure to activate your <code>nextflow-scrnaseq</code> environment from above. Then, inside the scRNAseq folder, begin the pipeline using the following command (ensuring you use the <code>cluster</code> profile to make use of the Slurm workflow manager).</p> <pre><code># Activate conda environment\nmamba activate nextflow-scrnaseq\n\n# Begin running the pipeline\nnextflow run process_raw_reads.nf -resume -profile cluster\n</code></pre>"},{"location":"NextFlow/scRNAseq/#customisation","title":"Customisation \u2699\ufe0f","text":"<p>There are several customisation options that are available within the <code>nextflow.config</code> file. While the defaults should be suitable for those with access to the M3 MASSIVE cluster genomics partition, for those without access, of for those who require different amounts of resources, there are ways to change these.</p> <p>In order to work with different technologies, and accommodate for differences in cell label structure (CLS), the STAR parameters <code>--soloType</code> and <code>--soloCBmatchWLtype</code> are set in a CLS-dependent manner. This is required, because the BD Rhapsody system has a complex barcode structure. The 10X Chromium system on the other hand has a simple barcode structure with a single barcode and single UMI. Additionally, the <code>--soloCBmatchWLtype = EditDist2</code> only works with <code>--soloType = CB_UMI_Complex</code>, and therefore <code>--soloCBmatchWLtype = 1MM multi Nbase pseudocounts</code> is used for 10X Chromium runs.</p> <ul> <li>For BD Rhapsody sequencing: <code>--soloType = CB_UMI_Complex</code> and <code>--soloCBmatchWLtype = EditDist2</code>.</li> <li>For 10X Chromium sequencing: <code>--soloType = CB_UMI_Simple</code> and <code>--soloCBmatchWLtype = 1MM multi Nbase pseudocounts</code>.</li> <li>Additionally, 10X Chromium runs use <code>--clipAdapterType = CellRanger4</code>.</li> </ul> <p>To adjust the <code>cluster</code> profile settings, stay within the appropriate section at the top of the file.</p> <p>Parameters</p> <p>Visit STAR documentation for explanations of all available options for STARsolo.</p> Option Description samples_csv The file path to your sample sheet outdir A new folder name to be created for your results trimgalore.quality The minimum quality before a sequence is truncated (default: <code>20</code>) trimgalore.adapter A custom adapter sequence for the R1 sequences (default: <code>'AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC'</code>) trimgalore.adapter2 A custom adapter sequence for the R2 sequences (default: <code>'AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT'</code>) starsolo.soloUMIdedup The type of UMI deduplication (default: <code>'1MM_CR'</code>) starsolo.soloUMIfiltering The type of UMI filtering for reads uniquely mapping to genes (default: <code>'MultiGeneUMI_CR'</code>) starsolo.soloCellFilter The method type and parameters for cell filtering (default: <code>'EmptyDrops_CR'</code>) starsolo.soloMultiMappers The counting method for reads mapping for multiple genes (default: <code>'EM'</code>) <p>Process</p> <p>These settings relate to resource allocation and cluster settings. FASTQC and TRIMGALORE steps can take longer than 4 hours for typical single-cell RNAseq file, and therefore the default option is to run these steps on the <code>comp</code> partition.</p> Option Description executor The workload manager (default: <code>'slurm'</code>) conda The conda environment to use (default: <code>'./environment.yaml'</code>) queueSize The maximum number of jobs to be submitted at any time (default: <code>12</code>) submitRateLimit The rate allowed for job submission \u2013 either a number of jobs per second (e.g. 20sec) or a number of jobs per time period (e.g. 20/5min) (default: <code>'1/2sec'</code>) memory The maximum global memory allowed for Nextflow to use (default: <code>'320 GB'</code>) FASTQC.memory Memory for FASTQC step to use (default: <code>'80 GB'</code>) FASTQC.cpus Number of CPUs for FASTQC step to use (default: <code>8</code>) FASTQC.clusterOptions Specific cluster options for FASTQC step (default: <code>'--time=8:00:00'</code>) TRIMGALORE.memory Memory for TRIMGALORE step to use (default: <code>'80 GB'</code>) TRIMGALORE.cpus Number of CPUs for TRIMGALORE step to use (default: <code>8</code>) TRIMGALORE.clusterOptions Specific cluster options for TRIMGALORE step (default : <code>'--time=8:00:00'</code>) STARSOLO.memory Memory for STARSOLO step to use (default: <code>'80 GB'</code>) STARSOLO.cpus Number of CPUs for STARSOLO step to use (default: <code>12</code>) STARSOLO.clusterOptions Specific cluster options for STARSOLO step (default : <code>'--time=4:00:00 --partition=genomics --qos=genomics'</code>) COLLECT_EXPORT_FILES.memory Memory for COLLECT_EXPORT_FILES step to use (default: <code>'32 GB'</code>) COLLECT_EXPORT_FILES.cpus Number of CPUs for COLLECT_EXPORT_FILES step to use (default: <code>8</code>) COLLECT_EXPORT_FILES.clusterOptions Specific cluster options for COLLECT_EXPORT_FILES step (default : <code>'--time=4:00:00 --partition=genomics --qos=genomics'</code>)"},{"location":"NextFlow/scRNAseq/#outputs","title":"Outputs","text":"<p>Several outputs will be copied from their respective Nextflow <code>work</code> directories to the output folder of your choice (default: <code>results</code>).</p> <p>Alignment summary utility script</p> <p> There is also a utility script in the main <code>scRNAseq</code> directory called <code>collect_alignment_summaries.sh</code>. This will navigate into each of the sample folders inside <code>results/STARsolo</code>, and retrieve some key information for you to validate that the alignment worked successfully (from the <code>GeneFull_Ex50pAS</code> subfolder). This can otherwise take quite some time to go through each folder if you have a lot of samples.</p> <ul> <li>After running this, a new file called <code>AlignmentSummary.txt</code> will be generated in the <code>scRNAseq</code> directory. Each sample will be listed by name, with the number of reads, percentage of reads with valid barcodes, and estimated number of cells.</li> <li>It will be immediately obvious that something has gone wrong if you see that the percentage of reads with valid barcodes is very low (e.g. <code>0.02</code> = 2% valid barcodes) \u2013 this is usually paired with a very low estimated cell number.</li> <li>This could indicate that you have used the wrong barcode version for your runs, and therefore the associated barcode whitelist used by the pipeline was incorrect.</li> </ul> <p>A successful example is shown below </p> <pre><code>Sample: Healthy1\nNumber of Reads,353152389\nReads With Valid Barcodes,0.950799\nEstimated Number of Cells,6623\n\nSample: Healthy2\nNumber of Reads,344989615\nReads With Valid Barcodes,0.948577\nEstimated Number of Cells,6631\n# etc...\n</code></pre>"},{"location":"NextFlow/scRNAseq/#collected-export-files","title":"Collected export files \ud83d\udce6","text":"<p>The main output will be a single archive file called <code>export_files.tar.gz</code> that you will take for further downstream pre-processing. It contains STARsolo outputs for each sample, with the respective subfolders described below.</p>"},{"location":"NextFlow/scRNAseq/#reports","title":"Reports \ud83d\udcc4","text":"<p>Within the <code>reports</code> folder, you will find the MultiQC outputs from pre- and post-trimming.</p>"},{"location":"NextFlow/scRNAseq/#starsolo","title":"STARsolo \u2b50","text":"<p>Contains the outputs for each sample from STARsolo, including various log files and package version information.</p> <p>The main output of interest here is a folder called <code>{sample}.Solo.out</code>, which houses subfolders called <code>Gene</code>, <code>GeneFull_Ex50pAS</code>, and <code>Velocyto</code>. It is this main folder for each sample that is added to <code>export_files.tar.gz</code>. * As you will use the gene count data from <code>GeneFull_Ex50pAS</code> downstream, it is a good idea to check the <code>Summary.csv</code> within this folder for each sample to ensure mapping was successful (or use the utility script above).   * One of the key values to inspect is <code>Reads With Valid Barcodes</code>, which should be &gt;0.8 (indicating at least 80% of reads had valid barcodes).   * If you note that this value is closer to 0.02 (i.e. ~2% had valid barcodes), you should double-check to make sure you specified the correct BD Rhapsody beads version. For instance, if you specified <code>BD_Enhanced_V1</code> but actually required <code>BD_Enhanced_V2</code>, the majority of your reads will not match the whitelist, and therefore the reads will be considered invalid.</p> <p>Folder structure</p> <p>Below is an example of the output structure for running one sample. The STARsolo folder would contain additional samples as required.</p> <pre><code>scRNAseq\n\u2514\u2500\u2500 results/\n    \u251c\u2500\u2500 export_files.tar.gz\n    \u251c\u2500\u2500 reports/\n    \u2502   \u251c\u2500\u2500 pretrim_multiqc_report.html\n    \u2502   \u2514\u2500\u2500 posttrim_multiqc_report.html\n    \u2514\u2500\u2500 STARsolo/\n        \u2514\u2500\u2500 sample1/\n            \u251c\u2500\u2500 sample1.Solo.out/\n            \u2502   \u251c\u2500\u2500 Gene/\n            \u2502   \u2502   \u251c\u2500\u2500 filtered/\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 barcodes.tsv.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 features.tsv.gz\n            \u2502   \u2502   \u2502   \u2514\u2500\u2500 matrix.mtx.gz\n            \u2502   \u2502   \u251c\u2500\u2500 raw/\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 barcodes.tsv.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 features.tsv.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 matrix.mtx.gz\n            \u2502   \u2502   \u2502   \u2514\u2500\u2500 UniqueAndMult-EM.mtx.gz\n            \u2502   \u2502   \u251c\u2500\u2500 Features.stats\n            \u2502   \u2502   \u251c\u2500\u2500 Summary.csv\n            \u2502   \u2502   \u2514\u2500\u2500 UMIperCellSorted.txt\n            \u2502   \u251c\u2500\u2500 GeneFull_Ex50pAS/\n            \u2502   \u2502   \u251c\u2500\u2500 filtered/\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 barcodes.tsv.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 features.tsv.gz\n            \u2502   \u2502   \u2502   \u2514\u2500\u2500 matrix.mtx.gz\n            \u2502   \u2502   \u251c\u2500\u2500 raw/\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 barcodes.tsv.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 features.tsv.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 matrix.mtx.gz\n            \u2502   \u2502   \u2502   \u2514\u2500\u2500 UniqueAndMult-EM.mtx.gz\n            \u2502   \u2502   \u251c\u2500\u2500 Features.stats\n            \u2502   \u2502   \u251c\u2500\u2500 Summary.csv\n            \u2502   \u2502   \u2514\u2500\u2500 UMIperCellSorted.txt\n            \u2502   \u251c\u2500\u2500 Velocyto/\n            \u2502   \u2502   \u251c\u2500\u2500 filtered/\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 ambiguous.mtx.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 barcodes.tsv.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 features.tsv.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 spliced.mtx.gz\n            \u2502   \u2502   \u2502   \u2514\u2500\u2500 unspliced.mtx.gz\n            \u2502   \u2502   \u251c\u2500\u2500 raw/\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 ambiguous.mtx.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 barcodes.tsv.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 features.tsv.gz\n            \u2502   \u2502   \u2502   \u251c\u2500\u2500 spliced.mtx.gz\n            \u2502   \u2502   \u2502   \u2514\u2500\u2500 unspliced.mtx.gz\n            \u2502   \u2502   \u251c\u2500\u2500 Features.stats\n            \u2502   \u2502   \u2514\u2500\u2500 Summary.csv\n            \u2502   \u2514\u2500\u2500 Barcodes.stats\n            \u251c\u2500\u2500 sample1.Log.final.out\n            \u251c\u2500\u2500 sample1.Log.out\n            \u251c\u2500\u2500 sample1.Log.progress.out\n            \u2514\u2500\u2500 versions.yml\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/","title":"Processing RNA sequencing data with nf-core","text":""},{"location":"RNAseq/rnaseq-nfcore/#overview","title":"Overview","text":"<p>Here we will describe the process for processing RNA sequencing data using the nf-core/rnaseq pipeline. This document was written as of version 3.14.0</p> <p>nf-core/rnaseq is a bioinformatics pipeline that can be used to analyse RNA sequencing data obtained from organisms with a reference genome and annotation. It takes a samplesheet and FASTQ files as input, performs quality control (QC), trimming and (pseudo-)alignment, and produces a gene expression matrix and extensive QC report.</p> <p>Full details of the pipeline and the many customisable options can be view on the pipeline website.</p> <p></p>"},{"location":"RNAseq/rnaseq-nfcore/#installation","title":"Installation","text":"<p>In this section, we discuss the installation process on the M3 MASSIVE cluster.</p>"},{"location":"RNAseq/rnaseq-nfcore/#create-nextflow-environment","title":"Create nextflow environment \ud83d\udc0d","text":"<p>To begin with, we need to create a new environment using mamba. Mamba is recommended here over conda due to its massively improved dependency solving speeds and parallel package downloading (among other reasons).</p> <pre><code># Create environment\nmamba create -n nextflow nextflow \\\n    salmon=1.10.0 fq fastqc umi_tools \\\n    trim-galore bbmap sortmerna samtools \\\n    picard stringtie bedtools rseqc \\\n    qualimap preseq multiqc subread \\\n    ucsc-bedgraphtobigwig ucsc-bedclip \\\n    bioconductor-deseq2\n\n# Activate environment\nmamba activate nextflow\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#download-and-compile-rsem","title":"Download and compile RSEM","text":"<p>RSEM is a software package for estimating gene and isoform expression levels from RNA-Seq data.</p> <pre><code># Download RSEM\ngit clone https://github.com/deweylab/RSEM\n\n# Enter the directory (RSEM) and compile\ncd RSEM; make\n</code></pre> <p>Make note of this directory for your run script so you can add this to your PATH variable.</p>"},{"location":"RNAseq/rnaseq-nfcore/#prepare-your-sample-sheet","title":"Prepare your sample sheet \u270f\ufe0f","text":"<p>You will need to have a sample sheet prepared that contains a sample name, the <code>fastq.gz</code> file paths, and the strandedness of the read files.</p> <p>If you are working with a single-ended sequencing run, leave the <code>fastq_2</code> column empty, but the header still needs to be included.</p> <p>For example, <code>samplesheet.csv</code>:</p> <pre><code>sample,fastq_1,fastq_2,strandedness\nCONTROL_REP1,AEG588A1_S1_L002_R1_001.fastq.gz,AEG588A1_S1_L002_R2_001.fastq.gz,auto\nCONTROL_REP1,AEG588A1_S1_L003_R1_001.fastq.gz,AEG588A1_S1_L003_R2_001.fastq.gz,auto\nCONTROL_REP1,AEG588A1_S1_L004_R1_001.fastq.gz,AEG588A1_S1_L004_R2_001.fastq.gz,auto\n</code></pre> <p>Each row represents a fastq file (single-end) or a pair of fastq files (paired end). Rows with the same sample identifier are considered technical replicates and merged automatically. The strandedness refers to the library preparation and will be automatically inferred if set to auto.</p>"},{"location":"RNAseq/rnaseq-nfcore/#run-the-pipeline","title":"Run the pipeline \ud83c\udf4f","text":""},{"location":"RNAseq/rnaseq-nfcore/#start-a-new-interactive-session","title":"Start a new interactive session","text":"<p>Firstly, we will start a new interactive session on the M3 MASSIVE cluster.</p> <pre><code>smux n --time=2-00:00:00 --mem=64GB --ntasks=1 --cpuspertask=12 -J nf-core/rnaseq\n</code></pre> <p>Once we are inside the interactive session, we need to select an appropriate version of the Java JDK to use. For the Nextflow pipeline we will be running, we need at least version 17+.</p> <pre><code># View available java JDK modules\nmodule avail java\n\n# Load an appropriate one (over version 17)\nmodule load java/openjdk-17.0.2\n\n# Can double-check the correct version is loaded\njava --version\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#test-your-set-up-optional","title":"Test your set-up (optional) \ud83e\uddba","text":"<p>This step is optional, but highly advisable for a first-time setup or when re-installing.</p> <pre><code>nextflow run nf-core/rnaseq -r 3.14.0 \\\n    -profile test \\\n    --outdir test \\\n    -resume \\\n    --skip-dupradar \\\n    --skip_markduplicates\n</code></pre> <ul> <li>We skip the <code>dupradar</code> step, because to install <code>bioconductor-dupradar</code>, mamba wants to downgrade <code>salmon</code> to a very early version, which is not ideal </li> <li>We also skip the <code>markduplicates</code> step because it is not recommended to remove duplicates anyway due to normal biological duplicates (i.e. there won't just be 1 copy of a given gene in a complete sample) </li> </ul>"},{"location":"RNAseq/rnaseq-nfcore/#download-genome-files","title":"Download genome files","text":"<p>To avoid issues with genome incompatibility with the version of STAR you are running, it is recommended to simply download the relevant genome fasta and GTF files using the following scripts, and then supply them directly to the function call.</p>"},{"location":"RNAseq/rnaseq-nfcore/#human-genome-files","title":"Human genome files \ud83d\udc68\ud83d\udc69","text":"01_retrieve_human_genome.sh<pre><code>#!/bin/bash\nVERSION=111\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/gtf/homo_sapiens/Homo_sapiens.GRCh38.$VERSION.gtf.gz\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#mouse-genome-files","title":"Mouse genome files \ud83d\udc01","text":"01_retrieve_mouse_genome.sh<pre><code>#!/bin/bash\nVERSION=111\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/fasta/mus_musculus/dna/Mus_musculus.GRCm39.dna_sm.primary_assembly.fa.gz\nwget -L ftp://ftp.ensembl.org/pub/release-$VERSION/gtf/mus_musculus/Mus_musculus.GRCm39.$VERSION.gtf.gz\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#run-your-rna-sequencing-reads","title":"Run your RNA sequencing reads \ud83d\udc01","text":"<p>To avoid typing the whole command out (and in case the pipeline crashes), create a script that will handle the process. Two examples are given here, with one for human samples, and one for mouse samples.</p> <ul> <li>You will need to replace the RSEM folder location with your own path from above.</li> <li>Using the <code>save_reference</code> option stores the formatted genome files to save time if you need to resume or restart the pipeline.</li> </ul>"},{"location":"RNAseq/rnaseq-nfcore/#human-run-script","title":"Human run script \ud83d\udc68\ud83d\udc69","text":"02_run_rnaseq_human.sh<pre><code>#!/bin/bash\nmodule load java/openjdk-17.0.2\nexport PATH=$PATH:/home/mmacowan/mf33/tools/RSEM/\n\nnextflow run nf-core/rnaseq -r 3.14.0 \\\n    --input samplesheet.csv \\\n    --outdir rnaseq_output \\\n    --fasta /home/mmacowan/mf33/scratch_nobackup/RNA/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz \\\n    --gtf /home/mmacowan/mf33/scratch_nobackup/RNA/Homo_sapiens.GRCh38.111.gtf.gz \\\n    --skip_dupradar \\\n    --skip_markduplicates \\\n    --save_reference \\\n    -resume\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#mouse-run-script","title":"Mouse run script \ud83d\udc01","text":"02_run_rnaseq_mouse.sh<pre><code>#!/bin/bash\nmodule load java/openjdk-17.0.2\nexport PATH=$PATH:\u201d/home/mmacowan/mf33/tools/RSEM/\u201d\n\nnextflow run nf-core/rnaseq -r 3.14.0 \\\n    --input samplesheet.csv \\\n    --outdir rnaseq_output \\\n    --fasta /home/mmacowan/mf33/scratch_nobackup/RNA/Mus_musculus.GRCm39.dna_sm.primary_assembly.fa.gz \\\n    --gtf /home/mmacowan/mf33/scratch_nobackup/RNA/Mus_musculus.GRCm39.111.gtf.gz \\\n    --skip_dupradar \\\n    --skip_markduplicates \\\n    --save_reference \\\n    -resume\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#import-data-into-r","title":"Import data into R","text":"<p>We have a standardised method for importing data into R. Luckily for us, the NF-CORE/rnaseq pipeline outputs are provided in <code>.rds</code> format as <code>SummarizedExperiment</code> objects, with bias-corrected gene counts without an offset.</p> <ul> <li><code>salmon.merged.gene_counts_length_scaled.rds</code></li> </ul> <p>There are two matrices provided to us: <code>counts</code> and <code>abundance</code>.</p> <ul> <li>The <code>abundance</code> matrix is the scaled and normalised transcripts per million (TPM) abundance. TPM explicitly erases information about library size. That is, it estimates the relative abundance of each transcript proportional to the total population of transcripts sampled in the experiment. Thus, you can imagine TPM, in a way, as a partition of unity \u2014 we want to assign a fraction of the total expression (whatever that may be) to transcript, regardless of whether our library is 10M fragments or 100M fragments.</li> <li>The <code>counts</code> matrix is a re-estimated counts table that aims to provide count-level data to be compatible with downstream tools such as DESeq2.</li> <li>The <code>tximport</code> package has a single function for importing transcript-level estimates. The type argument is used to specify what software was used for estimation. A simple list with matrices, <code>\"abundance\"</code>, <code>\"counts\"</code>, and <code>\"length\"</code>, is returned, where the transcript level information is summarized to the gene-level. Typically, abundance is provided by the quantification tools as TPM (transcripts-per-million), while the counts are estimated counts (possibly fractional), and the <code>\"length\"</code> matrix contains the effective gene lengths. The <code>\"length\"</code> matrix can be used to generate an offset matrix for downstream gene-level differential analysis of count matrices.</li> </ul>"},{"location":"RNAseq/rnaseq-nfcore/#r-code-for-import-and-voom-normalisation","title":"R code for import and voom-normalisation","text":"<p>Here we show our standard process for preparing RNAseq data for downstream analysis.</p> <pre><code># Load R packages\npkgs &lt;- c('knitr', 'here', 'SummarizedExperiment', 'biomaRt', 'edgeR', 'limma')\npacman::p_load(char = pkgs)\n\n# Import the bias-corrected counts from STAR Salmon\nrna_data &lt;- readRDS(here('input', 'salmon.merged.gene_counts_length_scaled.rds'))\n\n# Get Ensembl annotations\nensembl &lt;- useMart('ensembl', dataset = 'hsapiens_gene_ensembl')\n\nensemblIDsBronch &lt;- rownames(rna_bronch)\n\ngene_list &lt;- getBM(attributes = c('ensembl_gene_id', 'hgnc_symbol', 'gene_biotype'),\n                   filters = 'ensembl_gene_id', values = ensemblIDsBronch, mart = ensembl)\ncolnames(gene_list) &lt;- c(\"gene_id\", \"hgnc_symbol\", \"gene_biotype\")\ngene_list &lt;- filter(gene_list, !duplicated(gene_id))\n\n# Ensure that only genes in the STAR Salmon outputs are kept for the gene list\nrna_data &lt;- rna_data[rownames(rna_data) %in% gene_list$gene_id, ]\n\n# Add the ENSEMBL data to the rowData element\nrowData(rna_data) &lt;- merge(gene_list, rowData(rna_data), by = \"gene_id\", all = FALSE)\n\n# Load the RNA metadata\nmetadata_rna &lt;- read_csv(here('input', 'metadata_rna.csv'))\n\n# Sort the metadata rows to match the order of the abundance data\nrownames(metadata_rna) &lt;- metadata_rna$RNA_barcode\nmetadata_rna &lt;- metadata_rna[colnames(rna_data),]\n\n# Create a DGEList from the SummarizedExperiment object\nrna_data_dge &lt;- DGEList(assay(rna_data, 'counts'), \n                        samples = metadata_rna, \n                        group = metadata_rna$group,\n                        genes = rowData(rna_data),\n                        remove.zeros = TRUE)\n\n# Filter the DGEList based on the group information\ndesign &lt;- model.matrix(~ group, data = rna_data_dge$samples)\nkeep_min10 &lt;- filterByExpr(rna_data_dge, design, min.count = 10)\nrna_data_dge_min10 &lt;- rna_data_dge[keep_min10, ]\n\n# Calculate norm factors and perform voom normalisation\nrna_data_dge_min10 &lt;- calcNormFactors(rna_data_dge_min10)\nrna_data_dge_min10 &lt;- voom(rna_data_dge_min10, design, plot = TRUE)\n\n# Add the normalised abundance data from STAR Salmon and filter to match the counts data\nrna_data_dge_min10$abundance &lt;- as.matrix(assay(rna_bronch, 'abundance'))[keep_min10, ]\n\n# Select protein coding defined genes only\nrna_data_dge_min10 &lt;- rna_data_dge_min10[rna_data_dge_min10$genes$gene_biotype == \"protein_coding\" &amp; rna_data_dge_min10$genes$hgnc_symbol != \"\", ]\n\n# Add symbol as rowname\nrownames(rna_data_dge_min10) &lt;- rna_data_dge_min10$genes$gene_name\n\n# Save the DGEList\nsaveRDS(rna_data_dge_min10, here('input', 'rna_data_dge_min10.rds'))\n</code></pre>"},{"location":"RNAseq/rnaseq-nfcore/#rights","title":"Rights","text":"<p>NF-CORE/rnaseq</p> <p>There are many people to thank here for writing and maintaining the NF-CORE/rnaseq pipeline (see here). If you use this pipeline for your analysis, please cite it using the following doi: 10.5281/zenodo.1400710</p> <p>This document</p> <ul> <li>Copyright \u00a9 2024 \u2013 Mucosal Immunology Lab, Melbourne VIC, Australia</li> <li>Licence: These tools are provided under the MIT licence (see LICENSE file for details)</li> <li>Authors: M. Macowan</li> </ul>"}]}